{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80.,  6.])\n"
     ]
    }
   ],
   "source": [
    "x=torch.Tensor([5,2])\n",
    "y=torch.Tensor([16,3])\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torch:\n",
      "\n",
      "NAME\n",
      "    torch\n",
      "\n",
      "DESCRIPTION\n",
      "    The torch package contains data structures for multi-dimensional\n",
      "    tensors and mathematical operations over these are defined.\n",
      "    Additionally, it provides many utilities for efficient serializing of\n",
      "    Tensors and arbitrary types, and other useful utilities.\n",
      "    \n",
      "    It has a CUDA counterpart, that enables you to run your tensor computations\n",
      "    on an NVIDIA GPU with compute capability >= 3.0.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _C\n",
      "    __config__\n",
      "    __future__\n",
      "    _classes\n",
      "    _jit_internal\n",
      "    _namedtensor_internals\n",
      "    _ops\n",
      "    _six\n",
      "    _storage_docs\n",
      "    _tensor_docs\n",
      "    _tensor_str\n",
      "    _torch_docs\n",
      "    _utils\n",
      "    _utils_internal\n",
      "    autograd (package)\n",
      "    backends (package)\n",
      "    contrib (package)\n",
      "    cuda (package)\n",
      "    distributed (package)\n",
      "    distributions (package)\n",
      "    for_onnx (package)\n",
      "    functional\n",
      "    hub\n",
      "    jit (package)\n",
      "    multiprocessing (package)\n",
      "    nn (package)\n",
      "    onnx (package)\n",
      "    optim (package)\n",
      "    quantization (package)\n",
      "    quasirandom\n",
      "    random\n",
      "    serialization\n",
      "    sparse (package)\n",
      "    storage\n",
      "    tensor\n",
      "    testing (package)\n",
      "    utils (package)\n",
      "    version\n",
      "\n",
      "SUBMODULES\n",
      "    classes\n",
      "    cpp\n",
      "    ops\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        FatalError\n",
      "        torch.jit.Error\n",
      "    builtins.object\n",
      "        BoolTensor\n",
      "        ByteTensor\n",
      "        CharTensor\n",
      "        DoubleTensor\n",
      "        FloatTensor\n",
      "        IntTensor\n",
      "        LongTensor\n",
      "        ShortTensor\n",
      "        device\n",
      "        dtype\n",
      "        finfo\n",
      "        iinfo\n",
      "        layout\n",
      "        memory_format\n",
      "        qscheme\n",
      "        torch._C.Generator\n",
      "        torch.autograd.grad_mode.enable_grad\n",
      "        torch.autograd.grad_mode.no_grad\n",
      "        torch.autograd.grad_mode.set_grad_enabled\n",
      "    builtins.tuple(builtins.object)\n",
      "        Size\n",
      "    pybind11_builtins.pybind11_object(builtins.object)\n",
      "        torch._C.AggregationType\n",
      "        torch._C.Argument\n",
      "        torch._C.ArgumentSpec\n",
      "        torch._C.BenchmarkConfig\n",
      "        torch._C.BenchmarkExecutionStats\n",
      "        torch._C.Block\n",
      "        torch._C.BufferDict\n",
      "        torch._C.Code\n",
      "        torch._C.CompilationUnit\n",
      "        torch._C.CompleteArgumentSpec\n",
      "        torch._C.ConcreteModuleType\n",
      "        torch._C.ConcreteModuleTypeBuilder\n",
      "        torch._C.ErrorReport\n",
      "        torch._C.ExecutionPlan\n",
      "        torch._C.ExtraFilesMap\n",
      "        torch._C.FileCheck\n",
      "        torch._C.FunctionSchema\n",
      "        torch._C.Gradient\n",
      "        torch._C.Graph\n",
      "        torch._C.GraphExecutorState\n",
      "        torch._C.IODescriptor\n",
      "        torch._C.ModuleDict\n",
      "        torch._C.Node\n",
      "        torch._C.ParameterDict\n",
      "        torch._C.PyTorchFileReader\n",
      "        torch._C.PyTorchFileWriter\n",
      "        torch._C.ScriptMethod\n",
      "        torch._C.ScriptObject\n",
      "            torch._C.ScriptModule\n",
      "        torch._C.ThroughputBenchmark\n",
      "        torch._C.TracingState\n",
      "        torch._C.Type\n",
      "            torch._C.AnyType\n",
      "            torch._C.BoolType\n",
      "            torch._C.ClassType\n",
      "            torch._C.DictType\n",
      "            torch._C.FloatType\n",
      "            torch._C.IntType\n",
      "            torch._C.InterfaceType\n",
      "            torch._C.ListType\n",
      "            torch._C.NoneType\n",
      "            torch._C.NumberType\n",
      "            torch._C.OptionalType\n",
      "            torch._C.StringType\n",
      "            torch._C.TensorType\n",
      "            torch._C.TupleType\n",
      "        torch._C.Use\n",
      "        torch._C.Value\n",
      "        torch.jit.Future\n",
      "        torch.jit.ScriptFunction\n",
      "    torch._C.BoolStorageBase(builtins.object)\n",
      "        BoolStorage(torch._C.BoolStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.ByteStorageBase(builtins.object)\n",
      "        ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CharStorageBase(builtins.object)\n",
      "        CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.DoubleStorageBase(builtins.object)\n",
      "        DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.FloatStorageBase(builtins.object)\n",
      "        FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.IntStorageBase(builtins.object)\n",
      "        IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.LoggerBase(pybind11_builtins.pybind11_object)\n",
      "        torch._C.LockingLogger\n",
      "        torch._C.NoopLogger\n",
      "    torch._C.LongStorageBase(builtins.object)\n",
      "        LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.ShortStorageBase(builtins.object)\n",
      "        ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "    torch._C._TensorBase(builtins.object)\n",
      "        Tensor\n",
      "    torch.storage._StorageBase(builtins.object)\n",
      "        BoolStorage(torch._C.BoolStorageBase, torch.storage._StorageBase)\n",
      "        ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "        CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "        DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "        FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "        IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "        LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "        ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "    \n",
      "    class AggregationType(pybind11_builtins.pybind11_object)\n",
      "     |  Members:\n",
      "     |  \n",
      "     |  SUM\n",
      "     |  \n",
      "     |  AVG\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AggregationType\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__ = (...)\n",
      "     |      (self: object, arg0: object) -> bool\n",
      "     |  \n",
      "     |  __getstate__ = (...)\n",
      "     |      (self: object) -> int_\n",
      "     |  \n",
      "     |  __hash__ = (...)\n",
      "     |      (self: object) -> int_\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.AggregationType, arg0: int) -> None\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |      __int__(self: torch._C.AggregationType) -> int\n",
      "     |  \n",
      "     |  __ne__ = (...)\n",
      "     |      (self: object, arg0: object) -> bool\n",
      "     |  \n",
      "     |  __repr__ = (...)\n",
      "     |      (self: handle) -> str\n",
      "     |  \n",
      "     |  __setstate__ = (...)\n",
      "     |      (self: torch._C.AggregationType, arg0: int) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |  \n",
      "     |  name\n",
      "     |      (self: handle) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AVG = AggregationType.AVG\n",
      "     |  \n",
      "     |  SUM = AggregationType.SUM\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class AnyType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      AnyType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.AnyType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Argument(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Argument\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  N\n",
      "     |  \n",
      "     |  default_value\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ArgumentSpec(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ArgumentSpec\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BenchmarkConfig(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      BenchmarkConfig\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.BenchmarkConfig) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  num_calling_threads\n",
      "     |  \n",
      "     |  num_iters\n",
      "     |  \n",
      "     |  num_warmup_iters\n",
      "     |  \n",
      "     |  num_worker_threads\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BenchmarkExecutionStats(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      BenchmarkExecutionStats\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  latency_avg_ms\n",
      "     |  \n",
      "     |  num_iters\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Block(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Block\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  findAllNodes(...)\n",
      "     |      findAllNodes(self: torch._C.Block, kind: str, recurse: bool = True) -> List[torch::jit::Node]\n",
      "     |      \n",
      "     |      Find all nodes\n",
      "     |  \n",
      "     |  findNode(...)\n",
      "     |      findNode(self: torch._C.Block, kind: str, recurse: bool = True) -> torch::jit::Node\n",
      "     |      \n",
      "     |      Find Node\n",
      "     |  \n",
      "     |  inputs(...)\n",
      "     |      inputs(self: torch._C.Block) -> iterator\n",
      "     |  \n",
      "     |  nodes(...)\n",
      "     |      nodes(self: torch._C.Block) -> iterator\n",
      "     |  \n",
      "     |  outputs(...)\n",
      "     |      outputs(self: torch._C.Block) -> iterator\n",
      "     |  \n",
      "     |  paramNode(...)\n",
      "     |      paramNode(self: torch._C.Block) -> torch::jit::Node\n",
      "     |  \n",
      "     |  returnNode(...)\n",
      "     |      returnNode(self: torch._C.Block) -> torch::jit::Node\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BoolStorage(torch._C.BoolStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      BoolStorage\n",
      "     |      torch._C.BoolStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.BoolStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.BoolStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.BoolStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class BoolTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          def scale_channels(input, scale):\n",
      "     |              scale = scale.refine_names('C')\n",
      "     |              return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(False, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(4, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[True, True],\n",
      "     |                  [True, False],\n",
      "     |                  [True, True],\n",
      "     |                  [True, True]], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([ True, False,  True,  True], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=0)\n",
      "     |          tensor([ True, False], dtype=torch.bool)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(True, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2) < 0\n",
      "     |          >>> a\n",
      "     |          tensor([[ True,  True],\n",
      "     |                  [False,  True],\n",
      "     |                  [ True,  True],\n",
      "     |                  [False, False]])\n",
      "     |          >>> a.any(1)\n",
      "     |          tensor([ True,  True,  True, False])\n",
      "     |          >>> a.any(0)\n",
      "     |          tensor([True, True])\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16() -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool() -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of dense dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  imag(...)\n",
      "     |      imag() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.imag`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  real(...)\n",
      "     |      real() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.real`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of sparse dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, namedshape)\n",
      "     |      Unflattens the named dimension :attr:`dim`, viewing it in the shape\n",
      "     |      specified by :attr:`namedshape`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          namedshape: (iterable of ``(name, size)`` tuples).\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features'))\n",
      "     |          >>> imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128)))\n",
      "     |          >>> imgs.names, images.shape\n",
      "     |          (('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128]))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.bool\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class BoolType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      BoolType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.BoolType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BufferDict(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      BufferDict\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.BufferDict, arg0: torch._C.ScriptModule) -> None\n",
      "     |  \n",
      "     |  contains(...)\n",
      "     |      contains(self: torch._C.BufferDict, arg0: str) -> bool\n",
      "     |  \n",
      "     |  getattr(...)\n",
      "     |      getattr(self: torch._C.BufferDict, arg0: str) -> object\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      items(self: torch._C.BufferDict) -> List[Tuple[str, object]]\n",
      "     |  \n",
      "     |  setattr(...)\n",
      "     |      setattr(self: torch._C.BufferDict, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      ByteStorage\n",
      "     |      torch._C.ByteStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.ByteStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.ByteStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.ByteStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class ByteTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          def scale_channels(input, scale):\n",
      "     |              scale = scale.refine_names('C')\n",
      "     |              return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(False, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(4, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[True, True],\n",
      "     |                  [True, False],\n",
      "     |                  [True, True],\n",
      "     |                  [True, True]], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([ True, False,  True,  True], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=0)\n",
      "     |          tensor([ True, False], dtype=torch.bool)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(True, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2) < 0\n",
      "     |          >>> a\n",
      "     |          tensor([[ True,  True],\n",
      "     |                  [False,  True],\n",
      "     |                  [ True,  True],\n",
      "     |                  [False, False]])\n",
      "     |          >>> a.any(1)\n",
      "     |          tensor([ True,  True,  True, False])\n",
      "     |          >>> a.any(0)\n",
      "     |          tensor([True, True])\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16() -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool() -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of dense dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  imag(...)\n",
      "     |      imag() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.imag`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  real(...)\n",
      "     |      real() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.real`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of sparse dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, namedshape)\n",
      "     |      Unflattens the named dimension :attr:`dim`, viewing it in the shape\n",
      "     |      specified by :attr:`namedshape`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          namedshape: (iterable of ``(name, size)`` tuples).\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features'))\n",
      "     |          >>> imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128)))\n",
      "     |          >>> imgs.names, images.shape\n",
      "     |          (('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128]))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.uint8\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      CharStorage\n",
      "     |      torch._C.CharStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CharStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CharStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CharStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class CharTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          def scale_channels(input, scale):\n",
      "     |              scale = scale.refine_names('C')\n",
      "     |              return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(False, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(4, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[True, True],\n",
      "     |                  [True, False],\n",
      "     |                  [True, True],\n",
      "     |                  [True, True]], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([ True, False,  True,  True], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=0)\n",
      "     |          tensor([ True, False], dtype=torch.bool)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(True, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2) < 0\n",
      "     |          >>> a\n",
      "     |          tensor([[ True,  True],\n",
      "     |                  [False,  True],\n",
      "     |                  [ True,  True],\n",
      "     |                  [False, False]])\n",
      "     |          >>> a.any(1)\n",
      "     |          tensor([ True,  True,  True, False])\n",
      "     |          >>> a.any(0)\n",
      "     |          tensor([True, True])\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16() -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool() -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of dense dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  imag(...)\n",
      "     |      imag() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.imag`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  real(...)\n",
      "     |      real() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.real`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of sparse dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, namedshape)\n",
      "     |      Unflattens the named dimension :attr:`dim`, viewing it in the shape\n",
      "     |      specified by :attr:`namedshape`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          namedshape: (iterable of ``(name, size)`` tuples).\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features'))\n",
      "     |          >>> imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128)))\n",
      "     |          >>> imgs.names, images.shape\n",
      "     |          (('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128]))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int8\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class ClassType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      ClassType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ClassType, arg0: str) -> None\n",
      "     |  \n",
      "     |  name(...)\n",
      "     |      name(self: torch._C.ClassType) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Code(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Code\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  grad_executor_states(...)\n",
      "     |      grad_executor_states(self: torch._C.Code) -> List[torch::jit::GraphExecutorState]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class CompilationUnit(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      CompilationUnit\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.CompilationUnit) -> None\n",
      "     |  \n",
      "     |  define(...)\n",
      "     |      define(self: torch._C.CompilationUnit, arg0: str, arg1: Callable[[str], function]) -> None\n",
      "     |  \n",
      "     |  find_function(...)\n",
      "     |      find_function(self: torch._C.CompilationUnit, arg0: str) -> torch::jit::StrongFunctionPtr\n",
      "     |  \n",
      "     |  set_optimized(...)\n",
      "     |      set_optimized(self: torch._C.CompilationUnit, arg0: bool) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class CompleteArgumentSpec(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      CompleteArgumentSpec\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.CompleteArgumentSpec) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ConcreteModuleType(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ConcreteModuleType\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      dump(self: torch._C.ConcreteModuleType) -> None\n",
      "     |  \n",
      "     |  equals(...)\n",
      "     |      equals(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. equals(self: torch._C.ConcreteModuleType, arg0: torch._C.ConcreteModuleType) -> bool\n",
      "     |      \n",
      "     |      2. equals(self: torch._C.ConcreteModuleType, arg0: torch._C.ConcreteModuleTypeBuilder) -> bool\n",
      "     |  \n",
      "     |  get_attributes(...)\n",
      "     |      get_attributes(self: torch._C.ConcreteModuleType) -> Dict[str, Tuple[torch._C.Type, bool]]\n",
      "     |  \n",
      "     |  get_constants(...)\n",
      "     |      get_constants(self: torch._C.ConcreteModuleType) -> Dict[str, object]\n",
      "     |  \n",
      "     |  get_modules(...)\n",
      "     |      get_modules(self: torch._C.ConcreteModuleType) -> List[Tuple[str, torch._C.Type]]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_jit_type(...) from builtins.PyCapsule\n",
      "     |      from_jit_type(arg0: torch._C.Type) -> torch._C.ConcreteModuleType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  jit_type\n",
      "     |  \n",
      "     |  py_class\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ConcreteModuleTypeBuilder(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ConcreteModuleTypeBuilder\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ConcreteModuleTypeBuilder, arg0: object) -> None\n",
      "     |  \n",
      "     |  add_attribute(...)\n",
      "     |      add_attribute(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: torch._C.Type, arg2: bool) -> None\n",
      "     |  \n",
      "     |  add_constant(...)\n",
      "     |      add_constant(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  add_failed_attribute(...)\n",
      "     |      add_failed_attribute(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: str) -> None\n",
      "     |  \n",
      "     |  add_function_attribute(...)\n",
      "     |      add_function_attribute(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: torch._C.Type, arg2: object) -> None\n",
      "     |  \n",
      "     |  add_module(...)\n",
      "     |      add_module(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: torch::jit::script::ConcreteModuleType) -> None\n",
      "     |  \n",
      "     |  add_overload(...)\n",
      "     |      add_overload(self: torch._C.ConcreteModuleTypeBuilder, arg0: str, arg1: List[str]) -> None\n",
      "     |  \n",
      "     |  build(...)\n",
      "     |      build(self: torch._C.ConcreteModuleTypeBuilder) -> torch::jit::script::ConcreteModuleType\n",
      "     |  \n",
      "     |  equals(...)\n",
      "     |      equals(self: torch._C.ConcreteModuleTypeBuilder, arg0: torch._C.ConcreteModuleTypeBuilder) -> bool\n",
      "     |  \n",
      "     |  set_module_dict(...)\n",
      "     |      set_module_dict(self: torch._C.ConcreteModuleTypeBuilder) -> None\n",
      "     |  \n",
      "     |  set_module_list(...)\n",
      "     |      set_module_list(self: torch._C.ConcreteModuleTypeBuilder) -> None\n",
      "     |  \n",
      "     |  set_poisoned(...)\n",
      "     |      set_poisoned(self: torch._C.ConcreteModuleTypeBuilder) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class DictType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      DictType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.DictType, arg0: torch._C.Type, arg1: torch._C.Type) -> None\n",
      "     |  \n",
      "     |  getKeyType(...)\n",
      "     |      getKeyType(self: torch._C.DictType) -> torch._C.Type\n",
      "     |  \n",
      "     |  getValueType(...)\n",
      "     |      getValueType(self: torch._C.DictType) -> torch._C.Type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      DoubleStorage\n",
      "     |      torch._C.DoubleStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.DoubleStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.DoubleStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.DoubleStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class DoubleTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          def scale_channels(input, scale):\n",
      "     |              scale = scale.refine_names('C')\n",
      "     |              return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(False, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(4, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[True, True],\n",
      "     |                  [True, False],\n",
      "     |                  [True, True],\n",
      "     |                  [True, True]], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([ True, False,  True,  True], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=0)\n",
      "     |          tensor([ True, False], dtype=torch.bool)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(True, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2) < 0\n",
      "     |          >>> a\n",
      "     |          tensor([[ True,  True],\n",
      "     |                  [False,  True],\n",
      "     |                  [ True,  True],\n",
      "     |                  [False, False]])\n",
      "     |          >>> a.any(1)\n",
      "     |          tensor([ True,  True,  True, False])\n",
      "     |          >>> a.any(0)\n",
      "     |          tensor([True, True])\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16() -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool() -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of dense dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  imag(...)\n",
      "     |      imag() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.imag`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  real(...)\n",
      "     |      real() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.real`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of sparse dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, namedshape)\n",
      "     |      Unflattens the named dimension :attr:`dim`, viewing it in the shape\n",
      "     |      specified by :attr:`namedshape`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          namedshape: (iterable of ``(name, size)`` tuples).\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features'))\n",
      "     |          >>> imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128)))\n",
      "     |          >>> imgs.names, images.shape\n",
      "     |          (('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128]))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.float64\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class ErrorReport(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ErrorReport\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ErrorReport, arg0: torch._C._jit_tree_views.SourceRange) -> None\n",
      "     |  \n",
      "     |  what(...)\n",
      "     |      what(self: torch._C.ErrorReport) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ExecutionPlan(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ExecutionPlan\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ExtraFilesMap(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ExtraFilesMap\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |      __bool__(self: torch._C.ExtraFilesMap) -> bool\n",
      "     |      \n",
      "     |      Check whether the map is nonempty\n",
      "     |  \n",
      "     |  __delitem__(...)\n",
      "     |      __delitem__(self: torch._C.ExtraFilesMap, arg0: str) -> None\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      __getitem__(self: torch._C.ExtraFilesMap, arg0: str) -> str\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ExtraFilesMap) -> None\n",
      "     |  \n",
      "     |  __iter__(...)\n",
      "     |      __iter__(self: torch._C.ExtraFilesMap) -> iterator\n",
      "     |  \n",
      "     |  __len__(...)\n",
      "     |      __len__(self: torch._C.ExtraFilesMap) -> int\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.ExtraFilesMap) -> str\n",
      "     |      \n",
      "     |      Return the canonical string representation of this map.\n",
      "     |  \n",
      "     |  __setitem__(...)\n",
      "     |      __setitem__(self: torch._C.ExtraFilesMap, arg0: str, arg1: str) -> None\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      items(self: torch._C.ExtraFilesMap) -> iterator\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pybind11_module_local_v3__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FatalError(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FatalError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class FileCheck(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      FileCheck\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.FileCheck) -> None\n",
      "     |  \n",
      "     |  check(...)\n",
      "     |      check(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_count(...)\n",
      "     |      check_count(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. check_count(self: torch._C.FileCheck, arg0: str, arg1: int, arg2: bool) -> torch._C.FileCheck\n",
      "     |      \n",
      "     |      2. check_count(self: torch._C.FileCheck, arg0: str, arg1: int, arg2: bool) -> torch._C.FileCheck\n",
      "     |      \n",
      "     |      3. check_count(self: torch._C.FileCheck, str: str, count: int, exactly: bool = False) -> torch._C.FileCheck\n",
      "     |      \n",
      "     |      Check Count\n",
      "     |  \n",
      "     |  check_dag(...)\n",
      "     |      check_dag(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_next(...)\n",
      "     |      check_next(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_not(...)\n",
      "     |      check_not(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_same(...)\n",
      "     |      check_same(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  run(...)\n",
      "     |      run(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. run(self: torch._C.FileCheck, arg0: str) -> None\n",
      "     |      \n",
      "     |      2. run(self: torch._C.FileCheck, arg0: torch._C.Graph) -> None\n",
      "     |      \n",
      "     |      3. run(self: torch._C.FileCheck, checks_file: str, test_file: str) -> None\n",
      "     |      \n",
      "     |      Run\n",
      "     |      \n",
      "     |      4. run(self: torch._C.FileCheck, checks_file: str, graph: torch._C.Graph) -> None\n",
      "     |      \n",
      "     |      Run\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      FloatStorage\n",
      "     |      torch._C.FloatStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.FloatStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.FloatStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.FloatStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class FloatTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          def scale_channels(input, scale):\n",
      "     |              scale = scale.refine_names('C')\n",
      "     |              return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(False, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(4, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[True, True],\n",
      "     |                  [True, False],\n",
      "     |                  [True, True],\n",
      "     |                  [True, True]], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([ True, False,  True,  True], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=0)\n",
      "     |          tensor([ True, False], dtype=torch.bool)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(True, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2) < 0\n",
      "     |          >>> a\n",
      "     |          tensor([[ True,  True],\n",
      "     |                  [False,  True],\n",
      "     |                  [ True,  True],\n",
      "     |                  [False, False]])\n",
      "     |          >>> a.any(1)\n",
      "     |          tensor([ True,  True,  True, False])\n",
      "     |          >>> a.any(0)\n",
      "     |          tensor([True, True])\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16() -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool() -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of dense dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  imag(...)\n",
      "     |      imag() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.imag`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  real(...)\n",
      "     |      real() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.real`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of sparse dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, namedshape)\n",
      "     |      Unflattens the named dimension :attr:`dim`, viewing it in the shape\n",
      "     |      specified by :attr:`namedshape`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          namedshape: (iterable of ``(name, size)`` tuples).\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features'))\n",
      "     |          >>> imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128)))\n",
      "     |          >>> imgs.names, images.shape\n",
      "     |          (('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128]))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.float32\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class FloatType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      FloatType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.FloatType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FunctionSchema(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      FunctionSchema\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.FunctionSchema, arg0: torch._C.FunctionSchema) -> bool\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: torch._C.FunctionSchema) -> str\n",
      "     |  \n",
      "     |  is_backward_compatible_with(...)\n",
      "     |      is_backward_compatible_with(self: torch._C.FunctionSchema, arg0: torch._C.FunctionSchema) -> bool\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  arguments\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  overload_name\n",
      "     |  \n",
      "     |  returns\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Future(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Future\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Generator(builtins.object)\n",
      "     |  Generator(device='cpu') -> Generator\n",
      "     |  \n",
      "     |  Creates and returns a generator object which manages the state of the algorithm that\n",
      "     |  produces pseudo random numbers. Used as a keyword argument in many :ref:`inplace-random-sampling`\n",
      "     |  functions.\n",
      "     |  \n",
      "     |  Arguments:\n",
      "     |      device (:class:`torch.device`, optional): the desired device for the generator.\n",
      "     |  \n",
      "     |  Returns:\n",
      "     |      Generator: An torch.Generator object.\n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> g_cpu = torch.Generator()\n",
      "     |      >>> g_cuda = torch.Generator(device='cuda')\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  get_state(...)\n",
      "     |      Generator.get_state() -> Tensor\n",
      "     |      \n",
      "     |      Returns the Generator state as a ``torch.ByteTensor``.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Tensor: A ``torch.ByteTensor`` which contains all the necessary bits\n",
      "     |          to restore a Generator to a specific point in time.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu.get_state()\n",
      "     |  \n",
      "     |  initial_seed(...)\n",
      "     |      Generator.initial_seed() -> int\n",
      "     |      \n",
      "     |      Returns the initial seed for generating random numbers.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu.initial_seed()\n",
      "     |          2147483647\n",
      "     |  \n",
      "     |  manual_seed(...)\n",
      "     |      Generator.manual_seed(seed) -> Generator\n",
      "     |      \n",
      "     |      Sets the seed for generating random numbers. Returns a `torch.Generator` object.\n",
      "     |      It is recommended to set a large seed, i.e. a number that has a good balance of 0\n",
      "     |      and 1 bits. Avoid having many 0 bits in the seed.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          seed (int): The desired seed.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Generator: An torch.Generator object.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu.manual_seed(2147483647)\n",
      "     |  \n",
      "     |  seed(...)\n",
      "     |      Generator.seed() -> int\n",
      "     |      \n",
      "     |      Gets a non-deterministic random number from std::random_device or the current\n",
      "     |      time and uses it to seed a Generator.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu.seed()\n",
      "     |          1516516984916\n",
      "     |  \n",
      "     |  set_state(...)\n",
      "     |      Generator.set_state(new_state) -> void\n",
      "     |      \n",
      "     |      Sets the Generator state.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          new_state (torch.ByteTensor): The desired state.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu_other = torch.Generator()\n",
      "     |          >>> g_cpu.set_state(g_cpu_other.get_state())\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  device\n",
      "     |      Generator.device -> device\n",
      "     |      \n",
      "     |      Gets the current device of the generator.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> g_cpu = torch.Generator()\n",
      "     |          >>> g_cpu.device\n",
      "     |          device(type='cpu')\n",
      "    \n",
      "    class Gradient(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Gradient\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  df\n",
      "     |  \n",
      "     |  df_input_captured_inputs\n",
      "     |  \n",
      "     |  df_input_captured_outputs\n",
      "     |  \n",
      "     |  df_input_vjps\n",
      "     |  \n",
      "     |  df_output_vjps\n",
      "     |  \n",
      "     |  f\n",
      "     |  \n",
      "     |  f_real_outputs\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Graph(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Graph\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Graph) -> str\n",
      "     |  \n",
      "     |  addInput(...)\n",
      "     |      addInput(self: torch._C.Graph) -> torch::jit::Value\n",
      "     |  \n",
      "     |  appendNode(...)\n",
      "     |      appendNode(self: torch._C.Graph, arg0: torch::jit::Node) -> torch::jit::Node\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      copy(self: torch._C.Graph) -> torch._C.Graph\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. create(self: torch._C.Graph, arg0: str) -> torch::jit::Node\n",
      "     |      \n",
      "     |      2. create(self: torch._C.Graph, arg0: str, arg1: int) -> torch::jit::Node\n",
      "     |      \n",
      "     |      3. create(self: torch._C.Graph, arg0: str, arg1: List[torch::jit::Value]) -> torch::jit::Node\n",
      "     |      \n",
      "     |      4. create(self: torch._C.Graph, arg0: str, arg1: List[torch::jit::Value], arg2: int) -> torch::jit::Node\n",
      "     |  \n",
      "     |  createClone(...)\n",
      "     |      createClone(self: torch._C.Graph, arg0: torch::jit::Node, arg1: object) -> torch::jit::Node\n",
      "     |  \n",
      "     |  createFusionGroup(...)\n",
      "     |      createFusionGroup(self: torch._C.Graph) -> torch::jit::Node\n",
      "     |  \n",
      "     |  dump_alias_db(...)\n",
      "     |      dump_alias_db(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  eraseInput(...)\n",
      "     |      eraseInput(self: torch._C.Graph, arg0: int) -> None\n",
      "     |  \n",
      "     |  findAllNodes(...)\n",
      "     |      findAllNodes(self: torch._C.Graph, kind: str, recurse: bool = True) -> List[torch::jit::Node]\n",
      "     |      \n",
      "     |      Find all nodes\n",
      "     |  \n",
      "     |  findNode(...)\n",
      "     |      findNode(self: torch._C.Graph, kind: str, recurse: bool = True) -> torch::jit::Node\n",
      "     |      \n",
      "     |      Find Node\n",
      "     |  \n",
      "     |  inputs(...)\n",
      "     |      inputs(self: torch._C.Graph) -> iterator\n",
      "     |  \n",
      "     |  insertNode(...)\n",
      "     |      insertNode(self: torch._C.Graph, arg0: torch::jit::Node) -> torch::jit::Node\n",
      "     |  \n",
      "     |  lint(...)\n",
      "     |      lint(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  nodes(...)\n",
      "     |      nodes(self: torch._C.Graph) -> iterator\n",
      "     |  \n",
      "     |  outputs(...)\n",
      "     |      outputs(self: torch._C.Graph) -> iterator\n",
      "     |  \n",
      "     |  param_node(...)\n",
      "     |      param_node(self: torch._C.Graph) -> torch::jit::Node\n",
      "     |  \n",
      "     |  prependNode(...)\n",
      "     |      prependNode(self: torch._C.Graph, arg0: torch::jit::Node) -> torch::jit::Node\n",
      "     |  \n",
      "     |  registerOutput(...)\n",
      "     |      registerOutput(self: torch._C.Graph, arg0: torch::jit::Value) -> int\n",
      "     |  \n",
      "     |  return_node(...)\n",
      "     |      return_node(self: torch._C.Graph) -> torch::jit::Node\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Graph, print_source_ranges: bool = True) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class GraphExecutorState(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      GraphExecutorState\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  execution_plans\n",
      "     |  \n",
      "     |  fallback\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class IODescriptor(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      IODescriptor\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      IntStorage\n",
      "     |      torch._C.IntStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.IntStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.IntStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.IntStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class IntTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          def scale_channels(input, scale):\n",
      "     |              scale = scale.refine_names('C')\n",
      "     |              return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(False, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(4, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[True, True],\n",
      "     |                  [True, False],\n",
      "     |                  [True, True],\n",
      "     |                  [True, True]], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([ True, False,  True,  True], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=0)\n",
      "     |          tensor([ True, False], dtype=torch.bool)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(True, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2) < 0\n",
      "     |          >>> a\n",
      "     |          tensor([[ True,  True],\n",
      "     |                  [False,  True],\n",
      "     |                  [ True,  True],\n",
      "     |                  [False, False]])\n",
      "     |          >>> a.any(1)\n",
      "     |          tensor([ True,  True,  True, False])\n",
      "     |          >>> a.any(0)\n",
      "     |          tensor([True, True])\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16() -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool() -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of dense dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  imag(...)\n",
      "     |      imag() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.imag`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  real(...)\n",
      "     |      real() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.real`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of sparse dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, namedshape)\n",
      "     |      Unflattens the named dimension :attr:`dim`, viewing it in the shape\n",
      "     |      specified by :attr:`namedshape`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          namedshape: (iterable of ``(name, size)`` tuples).\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features'))\n",
      "     |          >>> imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128)))\n",
      "     |          >>> imgs.names, images.shape\n",
      "     |          (('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128]))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int32\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class IntType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      IntType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.IntType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class InterfaceType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      InterfaceType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.InterfaceType, arg0: str) -> None\n",
      "     |  \n",
      "     |  getMethodNames(...)\n",
      "     |      getMethodNames(self: torch._C.InterfaceType) -> List[str]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    JITException = class Error(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Error\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class ListType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      ListType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ListType, arg0: torch._C.Type) -> None\n",
      "     |  \n",
      "     |  getElementType(...)\n",
      "     |      getElementType(self: torch._C.ListType) -> torch._C.Type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  ofInts(...) from builtins.PyCapsule\n",
      "     |      ofInts() -> torch._C.ListType\n",
      "     |  \n",
      "     |  ofTensors(...) from builtins.PyCapsule\n",
      "     |      ofTensors() -> torch._C.ListType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class LockingLogger(LoggerBase)\n",
      "     |  Method resolution order:\n",
      "     |      LockingLogger\n",
      "     |      LoggerBase\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.LockingLogger) -> None\n",
      "     |  \n",
      "     |  get_counter_val(...)\n",
      "     |      get_counter_val(self: torch._C.LockingLogger, arg0: str) -> int\n",
      "     |  \n",
      "     |  set_aggregation_type(...)\n",
      "     |      set_aggregation_type(self: torch._C.LockingLogger, arg0: str, arg1: torch._C.AggregationType) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      LongStorage\n",
      "     |      torch._C.LongStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.LongStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.LongStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.LongStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class LongTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          def scale_channels(input, scale):\n",
      "     |              scale = scale.refine_names('C')\n",
      "     |              return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(False, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(4, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[True, True],\n",
      "     |                  [True, False],\n",
      "     |                  [True, True],\n",
      "     |                  [True, True]], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([ True, False,  True,  True], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=0)\n",
      "     |          tensor([ True, False], dtype=torch.bool)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(True, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2) < 0\n",
      "     |          >>> a\n",
      "     |          tensor([[ True,  True],\n",
      "     |                  [False,  True],\n",
      "     |                  [ True,  True],\n",
      "     |                  [False, False]])\n",
      "     |          >>> a.any(1)\n",
      "     |          tensor([ True,  True,  True, False])\n",
      "     |          >>> a.any(0)\n",
      "     |          tensor([True, True])\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16() -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool() -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of dense dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  imag(...)\n",
      "     |      imag() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.imag`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  real(...)\n",
      "     |      real() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.real`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of sparse dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, namedshape)\n",
      "     |      Unflattens the named dimension :attr:`dim`, viewing it in the shape\n",
      "     |      specified by :attr:`namedshape`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          namedshape: (iterable of ``(name, size)`` tuples).\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features'))\n",
      "     |          >>> imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128)))\n",
      "     |          >>> imgs.names, images.shape\n",
      "     |          (('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128]))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int64\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class ModuleDict(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ModuleDict\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ModuleDict, arg0: torch._C.ScriptModule) -> None\n",
      "     |  \n",
      "     |  contains(...)\n",
      "     |      contains(self: torch._C.ModuleDict, arg0: str) -> bool\n",
      "     |  \n",
      "     |  getattr(...)\n",
      "     |      getattr(self: torch._C.ModuleDict, arg0: str) -> object\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      items(self: torch._C.ModuleDict) -> List[Tuple[str, object]]\n",
      "     |  \n",
      "     |  setattr(...)\n",
      "     |      setattr(self: torch._C.ModuleDict, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Node(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Node\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  addBlock(...)\n",
      "     |      addBlock(self: torch._C.Node) -> torch._C.Block\n",
      "     |  \n",
      "     |  addInput(...)\n",
      "     |      addInput(self: torch._C.Node, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  addOutput(...)\n",
      "     |      addOutput(self: torch._C.Node) -> torch._C.Value\n",
      "     |  \n",
      "     |  attributeNames(...)\n",
      "     |      attributeNames(self: torch._C.Node) -> List[str]\n",
      "     |  \n",
      "     |  blocks(...)\n",
      "     |      blocks(self: torch._C.Node) -> iterator\n",
      "     |  \n",
      "     |  cconv(...)\n",
      "     |      cconv(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  copyAttributes(...)\n",
      "     |      copyAttributes(self: torch._C.Node, arg0: torch._C.Node) -> torch._C.Node\n",
      "     |  \n",
      "     |  destroy(...)\n",
      "     |      destroy(self: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  eraseOutput(...)\n",
      "     |      eraseOutput(self: torch._C.Node, arg0: int) -> None\n",
      "     |  \n",
      "     |  f(...)\n",
      "     |      f(self: torch._C.Node, arg0: str) -> float\n",
      "     |  \n",
      "     |  f_(...)\n",
      "     |      f_(self: torch._C.Node, arg0: str, arg1: float) -> torch._C.Node\n",
      "     |  \n",
      "     |  findAllNodes(...)\n",
      "     |      findAllNodes(self: torch._C.Node, kind: str, recurse: bool = True) -> List[torch._C.Node]\n",
      "     |      \n",
      "     |      Find all nodes\n",
      "     |  \n",
      "     |  findNode(...)\n",
      "     |      findNode(self: torch._C.Node, kind: str, recurse: bool = True) -> torch._C.Node\n",
      "     |      \n",
      "     |      Find Node\n",
      "     |  \n",
      "     |  fs(...)\n",
      "     |      fs(self: torch._C.Node, arg0: str) -> List[float]\n",
      "     |  \n",
      "     |  fs_(...)\n",
      "     |      fs_(self: torch._C.Node, arg0: str, arg1: List[float]) -> torch._C.Node\n",
      "     |  \n",
      "     |  g(...)\n",
      "     |      g(self: torch._C.Node, arg0: str) -> torch._C.Graph\n",
      "     |  \n",
      "     |  g_(...)\n",
      "     |      g_(self: torch._C.Node, arg0: str, arg1: torch._C.Graph) -> torch._C.Node\n",
      "     |  \n",
      "     |  gs(...)\n",
      "     |      gs(self: torch._C.Node, arg0: str) -> List[torch._C.Graph]\n",
      "     |  \n",
      "     |  gs_(...)\n",
      "     |      gs_(self: torch._C.Node, arg0: str, arg1: List[torch._C.Graph]) -> torch._C.Node\n",
      "     |  \n",
      "     |  hasAttribute(...)\n",
      "     |      hasAttribute(self: torch._C.Node, arg0: str) -> bool\n",
      "     |  \n",
      "     |  hasAttributes(...)\n",
      "     |      hasAttributes(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  hasMultipleOutputs(...)\n",
      "     |      hasMultipleOutputs(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  hasUses(...)\n",
      "     |      hasUses(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  i(...)\n",
      "     |      i(self: torch._C.Node, arg0: str) -> int\n",
      "     |  \n",
      "     |  i_(...)\n",
      "     |      i_(self: torch._C.Node, arg0: str, arg1: int) -> torch._C.Node\n",
      "     |  \n",
      "     |  input(...)\n",
      "     |      input(self: torch._C.Node) -> torch._C.Value\n",
      "     |  \n",
      "     |  inputs(...)\n",
      "     |      inputs(self: torch._C.Node) -> iterator\n",
      "     |  \n",
      "     |  inputsAt(...)\n",
      "     |      inputsAt(self: torch._C.Node, arg0: int) -> torch._C.Value\n",
      "     |  \n",
      "     |  insertAfter(...)\n",
      "     |      insertAfter(self: torch._C.Node, arg0: torch._C.Node) -> torch._C.Node\n",
      "     |  \n",
      "     |  insertBefore(...)\n",
      "     |      insertBefore(self: torch._C.Node, arg0: torch._C.Node) -> torch._C.Node\n",
      "     |  \n",
      "     |  is(...)\n",
      "     |      is(self: torch._C.Node, arg0: str) -> List[int]\n",
      "     |  \n",
      "     |  isNondeterministic(...)\n",
      "     |      isNondeterministic(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  is_(...)\n",
      "     |      is_(self: torch._C.Node, arg0: str, arg1: List[int]) -> torch._C.Node\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Node) -> Symbol\n",
      "     |  \n",
      "     |  kindOf(...)\n",
      "     |      kindOf(self: torch._C.Node, arg0: str) -> AttributeKind\n",
      "     |  \n",
      "     |  moveAfter(...)\n",
      "     |      moveAfter(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  moveBefore(...)\n",
      "     |      moveBefore(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  mustBeNone(...)\n",
      "     |      mustBeNone(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  output(...)\n",
      "     |      output(self: torch._C.Node) -> torch._C.Value\n",
      "     |  \n",
      "     |  outputs(...)\n",
      "     |      outputs(self: torch._C.Node) -> iterator\n",
      "     |  \n",
      "     |  outputsAt(...)\n",
      "     |      outputsAt(self: torch._C.Node, arg0: int) -> torch._C.Value\n",
      "     |  \n",
      "     |  outputsSize(...)\n",
      "     |      outputsSize(self: torch._C.Node) -> int\n",
      "     |  \n",
      "     |  pyname(...)\n",
      "     |      pyname(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  pyobj(...)\n",
      "     |      pyobj(self: torch._C.Node) -> object\n",
      "     |  \n",
      "     |  removeAllInputs(...)\n",
      "     |      removeAllInputs(self: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  removeAttribute(...)\n",
      "     |      removeAttribute(self: torch._C.Node, arg0: str) -> torch._C.Node\n",
      "     |  \n",
      "     |  removeInput(...)\n",
      "     |      removeInput(self: torch._C.Node, arg0: int) -> None\n",
      "     |  \n",
      "     |  replaceAllUsesWith(...)\n",
      "     |      replaceAllUsesWith(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  replaceInput(...)\n",
      "     |      replaceInput(self: torch._C.Node, arg0: int, arg1: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  replaceInputWith(...)\n",
      "     |      replaceInputWith(self: torch._C.Node, arg0: torch._C.Value, arg1: torch._C.Value) -> None\n",
      "     |  \n",
      "     |  s(...)\n",
      "     |      s(self: torch._C.Node, arg0: str) -> str\n",
      "     |  \n",
      "     |  s_(...)\n",
      "     |      s_(self: torch._C.Node, arg0: str, arg1: str) -> torch._C.Node\n",
      "     |  \n",
      "     |  scalar_args(...)\n",
      "     |      scalar_args(self: torch._C.Node) -> list\n",
      "     |  \n",
      "     |  scopeName(...)\n",
      "     |      scopeName(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  sourceRange(...)\n",
      "     |      sourceRange(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  ss(...)\n",
      "     |      ss(self: torch._C.Node, arg0: str) -> List[str]\n",
      "     |  \n",
      "     |  ss_(...)\n",
      "     |      ss_(self: torch._C.Node, arg0: str, arg1: List[str]) -> torch._C.Node\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t(self: torch._C.Node, arg0: str) -> at::Tensor\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_(self: torch._C.Node, arg0: str, arg1: at::Tensor) -> torch._C.Node\n",
      "     |  \n",
      "     |  ts(...)\n",
      "     |      ts(self: torch._C.Node, arg0: str) -> List[at::Tensor]\n",
      "     |  \n",
      "     |  ts_(...)\n",
      "     |      ts_(self: torch._C.Node, arg0: str, arg1: List[at::Tensor]) -> torch._C.Node\n",
      "     |  \n",
      "     |  z(...)\n",
      "     |      z(self: torch._C.Node, arg0: str) -> at::Tensor\n",
      "     |  \n",
      "     |  z_(...)\n",
      "     |      z_(self: torch._C.Node, arg0: str, arg1: at::Tensor) -> torch._C.Node\n",
      "     |  \n",
      "     |  zs(...)\n",
      "     |      zs(self: torch._C.Node, arg0: str) -> List[at::Tensor]\n",
      "     |  \n",
      "     |  zs_(...)\n",
      "     |      zs_(self: torch._C.Node, arg0: str, arg1: List[at::Tensor]) -> torch._C.Node\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class NoneType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      NoneType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.NoneType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class NoopLogger(LoggerBase)\n",
      "     |  Method resolution order:\n",
      "     |      NoopLogger\n",
      "     |      LoggerBase\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.NoopLogger) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class NumberType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      NumberType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.NumberType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class OptionalType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      OptionalType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.OptionalType, arg0: torch._C.Type) -> None\n",
      "     |  \n",
      "     |  getElementType(...)\n",
      "     |      getElementType(self: torch._C.OptionalType) -> torch._C.Type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  ofTensor(...) from builtins.PyCapsule\n",
      "     |      ofTensor() -> torch._C.OptionalType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ParameterDict(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ParameterDict\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ParameterDict, arg0: torch._C.ScriptModule) -> None\n",
      "     |  \n",
      "     |  contains(...)\n",
      "     |      contains(self: torch._C.ParameterDict, arg0: str) -> bool\n",
      "     |  \n",
      "     |  getattr(...)\n",
      "     |      getattr(self: torch._C.ParameterDict, arg0: str) -> object\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      items(self: torch._C.ParameterDict) -> List[Tuple[str, object]]\n",
      "     |  \n",
      "     |  setattr(...)\n",
      "     |      setattr(self: torch._C.ParameterDict, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class PyTorchFileReader(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      PyTorchFileReader\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. __init__(self: torch._C.PyTorchFileReader, arg0: str) -> None\n",
      "     |      \n",
      "     |      2. __init__(self: torch._C.PyTorchFileReader, arg0: object) -> None\n",
      "     |  \n",
      "     |  get_record(...)\n",
      "     |      get_record(self: torch._C.PyTorchFileReader, arg0: str) -> bytes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class PyTorchFileWriter(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      PyTorchFileWriter\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. __init__(self: torch._C.PyTorchFileWriter, arg0: str) -> None\n",
      "     |      \n",
      "     |      2. __init__(self: torch._C.PyTorchFileWriter, arg0: object) -> None\n",
      "     |      \n",
      "     |      3. __init__(self: torch._C.PyTorchFileWriter, arg0: Callable[[capsule, int], int]) -> None\n",
      "     |  \n",
      "     |  write_end_of_file(...)\n",
      "     |      write_end_of_file(self: torch._C.PyTorchFileWriter) -> None\n",
      "     |  \n",
      "     |  write_record(...)\n",
      "     |      write_record(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. write_record(self: torch._C.PyTorchFileWriter, arg0: str, arg1: str, arg2: int) -> None\n",
      "     |      \n",
      "     |      2. write_record(self: torch._C.PyTorchFileWriter, arg0: str, arg1: int, arg2: int) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptFunction(pybind11_builtins.pybind11_object)\n",
      "     |  Functionally equivalent to a :class:`ScriptModule`, but represents a single\n",
      "     |  function and does not have any attributes or Parameters.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ScriptFunction\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(...)\n",
      "     |      __call__(*args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_debug_state(...)\n",
      "     |      get_debug_state(self: torch._C.ScriptFunction) -> torch._C.GraphExecutorState\n",
      "     |  \n",
      "     |  graph_for = _graph_for(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(self: torch._C.ScriptFunction, filename: str, _extra_files: torch._C.ExtraFilesMap = ExtraFilesMap{}) -> None\n",
      "     |  \n",
      "     |  save_to_buffer(...)\n",
      "     |      save_to_buffer(self: torch._C.ScriptFunction, _extra_files: torch._C.ExtraFilesMap = ExtraFilesMap{}) -> bytes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  qualified_name\n",
      "     |  \n",
      "     |  schema\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptMethod(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ScriptMethod\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(...)\n",
      "     |      __call__(*args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  graph_for = _graph_for(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  schema\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptModule(ScriptObject)\n",
      "     |  Method resolution order:\n",
      "     |      ScriptModule\n",
      "     |      ScriptObject\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ScriptModule, arg0: str, arg1: torch::jit::script::CompilationUnit, arg2: bool) -> None\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(self: torch._C.ScriptModule, arg0: Callable[[torch._C.ScriptModule], None]) -> None\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      dump(self: torch._C.ScriptModule, code: bool = True, attrs: bool = True, params: bool = True) -> None\n",
      "     |  \n",
      "     |  dump_to_str(...)\n",
      "     |      dump_to_str(self: torch._C.ScriptModule, code: bool = True, attrs: bool = True, params: bool = True, indent: int = 0) -> str\n",
      "     |  \n",
      "     |  get_debug_state(...)\n",
      "     |      get_debug_state(self: torch._C.ScriptModule) -> torch._C.GraphExecutorState\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(self: torch._C.ScriptModule, filename: str, _extra_files: torch._C.ExtraFilesMap = ExtraFilesMap{}) -> None\n",
      "     |  \n",
      "     |  save_to_buffer(...)\n",
      "     |      save_to_buffer(self: torch._C.ScriptModule, _extra_files: torch._C.ExtraFilesMap = ExtraFilesMap{}) -> bytes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ScriptObject:\n",
      "     |  \n",
      "     |  __getattr__(...)\n",
      "     |      __getattr__(self: torch._C.ScriptObject, arg0: str) -> object\n",
      "     |  \n",
      "     |  getattr(...)\n",
      "     |      getattr(self: torch._C.ScriptObject, arg0: str) -> object\n",
      "     |  \n",
      "     |  hasattr(...)\n",
      "     |      hasattr(self: torch._C.ScriptObject, arg0: str) -> bool\n",
      "     |  \n",
      "     |  setattr(...)\n",
      "     |      setattr(self: torch._C.ScriptObject, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptObject(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ScriptObject\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getattr__(...)\n",
      "     |      __getattr__(self: torch._C.ScriptObject, arg0: str) -> object\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  getattr(...)\n",
      "     |      getattr(self: torch._C.ScriptObject, arg0: str) -> object\n",
      "     |  \n",
      "     |  hasattr(...)\n",
      "     |      hasattr(self: torch._C.ScriptObject, arg0: str) -> bool\n",
      "     |  \n",
      "     |  setattr(...)\n",
      "     |      setattr(self: torch._C.ScriptObject, arg0: str, arg1: object) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      ShortStorage\n",
      "     |      torch._C.ShortStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.ShortStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.ShortStorageBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.ShortStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Size of object in memory, in bytes.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class ShortTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          def scale_channels(input, scale):\n",
      "     |              scale = scale.refine_names('C')\n",
      "     |              return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(False, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(4, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[True, True],\n",
      "     |                  [True, False],\n",
      "     |                  [True, True],\n",
      "     |                  [True, True]], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([ True, False,  True,  True], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=0)\n",
      "     |          tensor([ True, False], dtype=torch.bool)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(True, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2) < 0\n",
      "     |          >>> a\n",
      "     |          tensor([[ True,  True],\n",
      "     |                  [False,  True],\n",
      "     |                  [ True,  True],\n",
      "     |                  [False, False]])\n",
      "     |          >>> a.any(1)\n",
      "     |          tensor([ True,  True,  True, False])\n",
      "     |          >>> a.any(0)\n",
      "     |          tensor([True, True])\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16() -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool() -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of dense dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  imag(...)\n",
      "     |      imag() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.imag`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  real(...)\n",
      "     |      real() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.real`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of sparse dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, namedshape)\n",
      "     |      Unflattens the named dimension :attr:`dim`, viewing it in the shape\n",
      "     |      specified by :attr:`namedshape`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          namedshape: (iterable of ``(name, size)`` tuples).\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features'))\n",
      "     |          >>> imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128)))\n",
      "     |          >>> imgs.names, images.shape\n",
      "     |          (('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128]))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int16\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class Size(builtins.tuple)\n",
      "     |  Size(iterable=(), /)\n",
      "     |  \n",
      "     |  Built-in immutable sequence.\n",
      "     |  \n",
      "     |  If no argument is given, the constructor returns an empty tuple.\n",
      "     |  If iterable is specified the tuple is initialized from iterable's items.\n",
      "     |  \n",
      "     |  If the argument is a tuple, the return value is the same object.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Size\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getnewargs__(self, /)\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class StringType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      StringType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.StringType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Tensor(torch._C._TensorBase)\n",
      "     |  Method resolution order:\n",
      "     |      Tensor\n",
      "     |      torch._C._TensorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  unflatten(self, dim, namedshape)\n",
      "     |      Unflattens the named dimension :attr:`dim`, viewing it in the shape\n",
      "     |      specified by :attr:`namedshape`.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          namedshape: (iterable of ``(name, size)`` tuples).\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features'))\n",
      "     |          >>> imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128)))\n",
      "     |          >>> imgs.names, images.shape\n",
      "     |          (('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128]))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C._TensorBase:\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          def scale_channels(input, scale):\n",
      "     |              scale = scale.refine_names('C')\n",
      "     |              return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(False, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(4, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[True, True],\n",
      "     |                  [True, False],\n",
      "     |                  [True, True],\n",
      "     |                  [True, True]], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([ True, False,  True,  True], dtype=torch.bool)\n",
      "     |          >>> a.all(dim=0)\n",
      "     |          tensor([ True, False], dtype=torch.bool)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are True, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(1, 2).bool()\n",
      "     |          >>> a\n",
      "     |          tensor([[False, True]], dtype=torch.bool)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(True, dtype=torch.bool)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are True, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2) < 0\n",
      "     |          >>> a\n",
      "     |          tensor([[ True,  True],\n",
      "     |                  [False,  True],\n",
      "     |                  [ True,  True],\n",
      "     |                  [False, False]])\n",
      "     |          >>> a.any(1)\n",
      "     |          tensor([ True,  True,  True, False])\n",
      "     |          >>> a.any(0)\n",
      "     |          tensor([True, True])\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16() -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool() -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of dense dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  imag(...)\n",
      "     |      imag() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.imag`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  real(...)\n",
      "     |      real() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.real`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns the number of sparse dimensions. Otherwise, this throws an error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C._TensorBase:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C._TensorBase:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_cuda\n",
      "     |      Is ``True`` if the Tensor is stored on the GPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  is_sparse\n",
      "     |  \n",
      "     |  layout\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "    \n",
      "    class TensorType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      TensorType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.TensorType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ThroughputBenchmark(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ThroughputBenchmark\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. __init__(self: torch._C.ThroughputBenchmark, arg0: torch._C.ScriptModule) -> None\n",
      "     |      \n",
      "     |      2. __init__(self: torch._C.ThroughputBenchmark, arg0: object) -> None\n",
      "     |  \n",
      "     |  add_input(...)\n",
      "     |      add_input(self: torch._C.ThroughputBenchmark, *args, **kwargs) -> None\n",
      "     |  \n",
      "     |  benchmark(...)\n",
      "     |      benchmark(self: torch._C.ThroughputBenchmark, arg0: torch._C.BenchmarkConfig) -> torch._C.BenchmarkExecutionStats\n",
      "     |  \n",
      "     |  run_once(...)\n",
      "     |      run_once(self: torch._C.ThroughputBenchmark, *args, **kwargs) -> object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class TracingState(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      TracingState\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.TracingState) -> str\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: torch._C.TracingState) -> str\n",
      "     |  \n",
      "     |  current_scope(...)\n",
      "     |      current_scope(self: torch._C.TracingState) -> str\n",
      "     |  \n",
      "     |  graph(...)\n",
      "     |      graph(self: torch._C.TracingState) -> torch._C.Graph\n",
      "     |  \n",
      "     |  pop_scope(...)\n",
      "     |      pop_scope(self: torch._C.TracingState) -> None\n",
      "     |  \n",
      "     |  push_scope(...)\n",
      "     |      push_scope(self: torch._C.TracingState, arg0: str) -> None\n",
      "     |  \n",
      "     |  set_graph(...)\n",
      "     |      set_graph(self: torch._C.TracingState, arg0: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class TupleType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      TupleType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.TupleType, arg0: List[torch._C.Type]) -> None\n",
      "     |  \n",
      "     |  elements(...)\n",
      "     |      elements(self: torch._C.TupleType) -> List[torch._C.Type]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Type(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. sizes(self: torch._C.Type) -> object\n",
      "     |      \n",
      "     |      2. sizes(self: torch._C.Type) -> object\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Use(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Use\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  offset\n",
      "     |  \n",
      "     |  user\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Value(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Value\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Value) -> str\n",
      "     |  \n",
      "     |  copyMetadata(...)\n",
      "     |      copyMetadata(self: torch._C.Value, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  debugName(...)\n",
      "     |      debugName(self: torch._C.Value) -> str\n",
      "     |  \n",
      "     |  inferTypeFrom(...)\n",
      "     |      inferTypeFrom(self: torch._C.Value, arg0: at::Tensor) -> None\n",
      "     |  \n",
      "     |  isCompleteTensor(...)\n",
      "     |      isCompleteTensor(self: torch._C.Value) -> bool\n",
      "     |  \n",
      "     |  node(...)\n",
      "     |      node(self: torch._C.Value) -> torch::jit::Node\n",
      "     |  \n",
      "     |  offset(...)\n",
      "     |      offset(self: torch._C.Value) -> int\n",
      "     |  \n",
      "     |  replaceAllUsesWith(...)\n",
      "     |      replaceAllUsesWith(self: torch._C.Value, arg0: torch._C.Value) -> None\n",
      "     |  \n",
      "     |  requires_grad(...)\n",
      "     |      requires_grad(self: torch._C.Value) -> bool\n",
      "     |  \n",
      "     |  setDebugName(...)\n",
      "     |      setDebugName(self: torch._C.Value, arg0: str) -> torch._C.Value\n",
      "     |  \n",
      "     |  setType(...)\n",
      "     |      setType(self: torch._C.Value, arg0: c10::Type) -> torch._C.Value\n",
      "     |  \n",
      "     |  setTypeAs(...)\n",
      "     |      setTypeAs(self: torch._C.Value, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  toIValue(...)\n",
      "     |      toIValue(self: torch._C.Value) -> Optional[IValue]\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. type(self: torch._C.Value) -> c10::Type\n",
      "     |      \n",
      "     |      2. type(self: torch._C.Value) -> c10::Type\n",
      "     |  \n",
      "     |  unique(...)\n",
      "     |      unique(self: torch._C.Value) -> int\n",
      "     |  \n",
      "     |  uses(...)\n",
      "     |      uses(self: torch._C.Value) -> List[torch::jit::Use]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class device(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  index\n",
      "     |  \n",
      "     |  type\n",
      "    \n",
      "    class dtype(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  is_floating_point\n",
      "     |  \n",
      "     |  is_signed\n",
      "    \n",
      "    class enable_grad(builtins.object)\n",
      "     |  Context-manager that enables gradient calculation.\n",
      "     |  \n",
      "     |  Enables gradient calculation, if it has been disabled via :class:`~no_grad`\n",
      "     |  or :class:`~set_grad_enabled`.\n",
      "     |  \n",
      "     |  This context manager is thread local; it will not affect computation\n",
      "     |  in other threads.\n",
      "     |  \n",
      "     |  Also functions as a decorator.\n",
      "     |  \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> x = torch.tensor([1], requires_grad=True)\n",
      "     |      >>> with torch.no_grad():\n",
      "     |      ...   with torch.enable_grad():\n",
      "     |      ...     y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      True\n",
      "     |      >>> y.backward()\n",
      "     |      >>> x.grad\n",
      "     |      >>> @torch.enable_grad()\n",
      "     |      ... def doubler(x):\n",
      "     |      ...     return x * 2\n",
      "     |      >>> with torch.no_grad():\n",
      "     |      ...     z = doubler(x)\n",
      "     |      >>> z.requires_grad\n",
      "     |      True\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, func)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class finfo(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  bits\n",
      "     |  \n",
      "     |  eps\n",
      "     |  \n",
      "     |  max\n",
      "     |  \n",
      "     |  min\n",
      "     |  \n",
      "     |  tiny\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class iinfo(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  bits\n",
      "     |  \n",
      "     |  max\n",
      "     |  \n",
      "     |  min\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class layout(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "    \n",
      "    class memory_format(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "    \n",
      "    class no_grad(builtins.object)\n",
      "     |  Context-manager that disabled gradient calculation.\n",
      "     |  \n",
      "     |  Disabling gradient calculation is useful for inference, when you are sure\n",
      "     |  that you will not call :meth:`Tensor.backward()`. It will reduce memory\n",
      "     |  consumption for computations that would otherwise have `requires_grad=True`.\n",
      "     |  \n",
      "     |  In this mode, the result of every computation will have\n",
      "     |  `requires_grad=False`, even when the inputs have `requires_grad=True`.\n",
      "     |  \n",
      "     |  This mode has no effect when using :class:`~enable_grad` context manager .\n",
      "     |  \n",
      "     |  This context manager is thread local; it will not affect computation\n",
      "     |  in other threads.\n",
      "     |  \n",
      "     |  Also functions as a decorator.\n",
      "     |  \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> x = torch.tensor([1], requires_grad=True)\n",
      "     |      >>> with torch.no_grad():\n",
      "     |      ...   y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      False\n",
      "     |      >>> @torch.no_grad()\n",
      "     |      ... def doubler(x):\n",
      "     |      ...     return x * 2\n",
      "     |      >>> z = doubler(x)\n",
      "     |      >>> z.requires_grad\n",
      "     |      False\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, func)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class qscheme(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "    \n",
      "    class set_grad_enabled(builtins.object)\n",
      "     |  set_grad_enabled(mode)\n",
      "     |  \n",
      "     |  Context-manager that sets gradient calculation to on or off.\n",
      "     |  \n",
      "     |  ``set_grad_enabled`` will enable or disable grads based on its argument :attr:`mode`.\n",
      "     |  It can be used as a context-manager or as a function.\n",
      "     |  \n",
      "     |  When using :class:`~enable_grad` context manager, :class:`~set_grad_enabled(False)`\n",
      "     |  has no effect.\n",
      "     |  \n",
      "     |  This context manager is thread local; it will not affect computation\n",
      "     |  in other threads.\n",
      "     |  \n",
      "     |  Arguments:\n",
      "     |      mode (bool): Flag whether to enable grad (``True``), or disable\n",
      "     |                   (``False``). This can be used to conditionally enable\n",
      "     |                   gradients.\n",
      "     |  \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> x = torch.tensor([1], requires_grad=True)\n",
      "     |      >>> is_train = False\n",
      "     |      >>> with torch.set_grad_enabled(is_train):\n",
      "     |      ...   y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      False\n",
      "     |      >>> torch.set_grad_enabled(True)\n",
      "     |      >>> y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      True\n",
      "     |      >>> torch.set_grad_enabled(False)\n",
      "     |      >>> y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      False\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  __init__(self, mode)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    chunk(...)\n",
      "        chunk(input, chunks, dim=0) -> List of Tensors\n",
      "        \n",
      "        Splits a tensor into a specific number of chunks.\n",
      "        \n",
      "        Last chunk will be smaller if the tensor size along the given dimension\n",
      "        :attr:`dim` is not divisible by :attr:`chunks`.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): the tensor to split\n",
      "            chunks (int): number of chunks to return\n",
      "            dim (int): dimension along which to split the tensor\n",
      "    \n",
      "    fork(...) method of builtins.PyCapsule instance\n",
      "        fork(*args) -> torch._C.Future\n",
      "    \n",
      "    get_default_dtype(...)\n",
      "        get_default_dtype() -> torch.dtype\n",
      "        \n",
      "        Get the current default floating point :class:`torch.dtype`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.get_default_dtype()  # initial default for floating point is torch.float32\n",
      "            torch.float32\n",
      "            >>> torch.set_default_dtype(torch.float64)\n",
      "            >>> torch.get_default_dtype()  # default is now changed to torch.float64\n",
      "            torch.float64\n",
      "            >>> torch.set_default_tensor_type(torch.FloatTensor)  # setting tensor type also affects this\n",
      "            >>> torch.get_default_dtype()  # changed to torch.float32, the dtype for torch.FloatTensor\n",
      "            torch.float32\n",
      "    \n",
      "    get_num_interop_threads(...)\n",
      "        get_num_interop_threads() -> int\n",
      "        \n",
      "        Returns the number of threads used for inter-op parallelism on CPU\n",
      "        (e.g. in JIT interpreter)\n",
      "    \n",
      "    get_num_threads(...)\n",
      "        get_num_threads() -> int\n",
      "        \n",
      "        Returns the number of threads used for parallelizing CPU operations\n",
      "    \n",
      "    get_rng_state()\n",
      "        Returns the random number generator state as a `torch.ByteTensor`.\n",
      "    \n",
      "    import_ir_module(...) method of builtins.PyCapsule instance\n",
      "        import_ir_module(arg0: torch._C.CompilationUnit, arg1: str, arg2: object, arg3: torch._C.ExtraFilesMap) -> torch._C.ScriptModule\n",
      "    \n",
      "    import_ir_module_from_buffer(...) method of builtins.PyCapsule instance\n",
      "        import_ir_module_from_buffer(arg0: torch._C.CompilationUnit, arg1: str, arg2: object, arg3: torch._C.ExtraFilesMap) -> torch._C.ScriptModule\n",
      "    \n",
      "    initial_seed()\n",
      "        Returns the initial seed for generating random numbers as a\n",
      "        Python `long`.\n",
      "    \n",
      "    is_anomaly_enabled(...)\n",
      "    \n",
      "    is_grad_enabled(...)\n",
      "    \n",
      "    is_storage(obj)\n",
      "        Returns True if `obj` is a PyTorch storage object.\n",
      "        \n",
      "        Args:\n",
      "            obj (Object): Object to test\n",
      "    \n",
      "    is_tensor(obj)\n",
      "        Returns True if `obj` is a PyTorch tensor.\n",
      "        \n",
      "        Args:\n",
      "            obj (Object): Object to test\n",
      "    \n",
      "    load(f, map_location=None, pickle_module=<module 'pickle' from 'C:\\\\Users\\\\Salar\\\\Anaconda3\\\\lib\\\\pickle.py'>, **pickle_load_args)\n",
      "        Loads an object saved with :func:`torch.save` from a file.\n",
      "        \n",
      "        :func:`torch.load` uses Python's unpickling facilities but treats storages,\n",
      "        which underlie tensors, specially. They are first deserialized on the\n",
      "        CPU and are then moved to the device they were saved from. If this fails\n",
      "        (e.g. because the run time system doesn't have certain devices), an exception\n",
      "        is raised. However, storages can be dynamically remapped to an alternative\n",
      "        set of devices using the :attr:`map_location` argument.\n",
      "        \n",
      "        If :attr:`map_location` is a callable, it will be called once for each serialized\n",
      "        storage with two arguments: storage and location. The storage argument\n",
      "        will be the initial deserialization of the storage, residing on the CPU.\n",
      "        Each serialized storage has a location tag associated with it which\n",
      "        identifies the device it was saved from, and this tag is the second\n",
      "        argument passed to :attr:`map_location`. The builtin location tags are ``'cpu'``\n",
      "        for CPU tensors and ``'cuda:device_id'`` (e.g. ``'cuda:2'``) for CUDA tensors.\n",
      "        :attr:`map_location` should return either ``None`` or a storage. If\n",
      "        :attr:`map_location` returns a storage, it will be used as the final deserialized\n",
      "        object, already moved to the right device. Otherwise, :func:`torch.load` will\n",
      "        fall back to the default behavior, as if :attr:`map_location` wasn't specified.\n",
      "        \n",
      "        If :attr:`map_location` is a :class:`torch.device` object or a string contraining\n",
      "        a device tag, it indicates the location where all tensors should be loaded.\n",
      "        \n",
      "        Otherwise, if :attr:`map_location` is a dict, it will be used to remap location tags\n",
      "        appearing in the file (keys), to ones that specify where to put the\n",
      "        storages (values).\n",
      "        \n",
      "        User extensions can register their own location tags and tagging and\n",
      "        deserialization methods using :func:`torch.serialization.register_package`.\n",
      "        \n",
      "        Args:\n",
      "            f: a file-like object (has to implement :meth:`read`, :meth`readline`, :meth`tell`, and :meth`seek`),\n",
      "                or a string containing a file name\n",
      "            map_location: a function, :class:`torch.device`, string or a dict specifying how to remap storage\n",
      "                locations\n",
      "            pickle_module: module used for unpickling metadata and objects (has to\n",
      "                match the :attr:`pickle_module` used to serialize file)\n",
      "            pickle_load_args: (Python 3 only) optional keyword arguments passed over to\n",
      "                :func:`pickle_module.load` and :func:`pickle_module.Unpickler`, e.g.,\n",
      "                :attr:`errors=...`.\n",
      "        \n",
      "        .. note::\n",
      "            When you call :func:`torch.load()` on a file which contains GPU tensors, those tensors\n",
      "            will be loaded to GPU by default. You can call ``torch.load(.., map_location='cpu')``\n",
      "            and then :meth:`load_state_dict` to avoid GPU RAM surge when loading a model checkpoint.\n",
      "        \n",
      "        .. note::\n",
      "            By default, we decode byte strings as ``utf-8``.  This is to avoid a common error\n",
      "            case ``UnicodeDecodeError: 'ascii' codec can't decode byte 0x...``\n",
      "            when loading files saved by Python 2 in Python 3.  If this default\n",
      "            is incorrect, you may use an extra :attr:`encoding` keyword argument to specify how\n",
      "            these objects should be loaded, e.g., :attr:`encoding='latin1'` decodes them\n",
      "            to strings using ``latin1`` encoding, and :attr:`encoding='bytes'` keeps them\n",
      "            as byte arrays which can be decoded later with ``byte_array.decode(...)``.\n",
      "        \n",
      "        Example:\n",
      "            >>> torch.load('tensors.pt')\n",
      "            # Load all tensors onto the CPU\n",
      "            >>> torch.load('tensors.pt', map_location=torch.device('cpu'))\n",
      "            # Load all tensors onto the CPU, using a function\n",
      "            >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage)\n",
      "            # Load all tensors onto GPU 1\n",
      "            >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1))\n",
      "            # Map tensors from GPU 1 to GPU 0\n",
      "            >>> torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'})\n",
      "            # Load tensor from io.BytesIO object\n",
      "            >>> with open('tensor.pt', 'rb') as f:\n",
      "                    buffer = io.BytesIO(f.read())\n",
      "            >>> torch.load(buffer)\n",
      "            # Load a module with 'ascii' encoding for unpickling\n",
      "            >>> torch.load('module.pt', encoding='ascii')\n",
      "    \n",
      "    manual_seed(seed)\n",
      "        Sets the seed for generating random numbers. Returns a\n",
      "        `torch.Generator` object.\n",
      "        \n",
      "        Args:\n",
      "            seed (int): The desired seed.\n",
      "    \n",
      "    matmul(...)\n",
      "        matmul(input, other, out=None) -> Tensor\n",
      "        \n",
      "        Matrix product of two tensors.\n",
      "        \n",
      "        The behavior depends on the dimensionality of the tensors as follows:\n",
      "        \n",
      "        - If both tensors are 1-dimensional, the dot product (scalar) is returned.\n",
      "        - If both arguments are 2-dimensional, the matrix-matrix product is returned.\n",
      "        - If the first argument is 1-dimensional and the second argument is 2-dimensional,\n",
      "          a 1 is prepended to its dimension for the purpose of the matrix multiply.\n",
      "          After the matrix multiply, the prepended dimension is removed.\n",
      "        - If the first argument is 2-dimensional and the second argument is 1-dimensional,\n",
      "          the matrix-vector product is returned.\n",
      "        - If both arguments are at least 1-dimensional and at least one argument is\n",
      "          N-dimensional (where N > 2), then a batched matrix multiply is returned.  If the first\n",
      "          argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the\n",
      "          batched matrix multiply and removed after.  If the second argument is 1-dimensional, a\n",
      "          1 is appended to its dimension for the purpose of the batched matrix multiple and removed after.\n",
      "          The non-matrix (i.e. batch) dimensions are :ref:`broadcasted <broadcasting-semantics>` (and thus\n",
      "          must be broadcastable).  For example, if :attr:`input` is a\n",
      "          :math:`(j \\times 1 \\times n \\times m)` tensor and :attr:`other` is a :math:`(k \\times m \\times p)`\n",
      "          tensor, :attr:`out` will be an :math:`(j \\times k \\times n \\times p)` tensor.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            The 1-dimensional dot product version of this function does not support an :attr:`out` parameter.\n",
      "        \n",
      "        Arguments:\n",
      "            input (Tensor): the first tensor to be multiplied\n",
      "            other (Tensor): the second tensor to be multiplied\n",
      "            out (Tensor, optional): the output tensor.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> # vector x vector\n",
      "            >>> tensor1 = torch.randn(3)\n",
      "            >>> tensor2 = torch.randn(3)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([])\n",
      "            >>> # matrix x vector\n",
      "            >>> tensor1 = torch.randn(3, 4)\n",
      "            >>> tensor2 = torch.randn(4)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([3])\n",
      "            >>> # batched matrix x broadcasted vector\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(4)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3])\n",
      "            >>> # batched matrix x batched matrix\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(10, 4, 5)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3, 5])\n",
      "            >>> # batched matrix x broadcasted matrix\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(4, 5)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3, 5])\n",
      "    \n",
      "    merge_type_from_type_comment(...) method of builtins.PyCapsule instance\n",
      "        merge_type_from_type_comment(arg0: torch._C._jit_tree_views.Decl, arg1: torch._C._jit_tree_views.Decl, arg2: bool) -> torch._C._jit_tree_views.Decl\n",
      "    \n",
      "    parse_ir(...) method of builtins.PyCapsule instance\n",
      "        parse_ir(arg0: str) -> torch::jit::Graph\n",
      "    \n",
      "    parse_schema(...) method of builtins.PyCapsule instance\n",
      "        parse_schema(arg0: str) -> c10::FunctionSchema\n",
      "    \n",
      "    parse_type_comment(...) method of builtins.PyCapsule instance\n",
      "        parse_type_comment(arg0: str) -> torch._C._jit_tree_views.Decl\n",
      "    \n",
      "    rand(...)\n",
      "        rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with random numbers from a uniform distribution\n",
      "        on the interval :math:`[0, 1)`\n",
      "        \n",
      "        The shape of the tensor is defined by the variable argument :attr:`size`.\n",
      "        \n",
      "        Args:\n",
      "            size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "                Can be a variable number of arguments or a collection like a list or tuple.\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.rand(4)\n",
      "            tensor([ 0.5204,  0.2503,  0.3525,  0.5673])\n",
      "            >>> torch.rand(2, 3)\n",
      "            tensor([[ 0.8237,  0.5781,  0.6879],\n",
      "                    [ 0.3816,  0.7249,  0.0998]])\n",
      "    \n",
      "    randn(...)\n",
      "        randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with random numbers from a normal distribution\n",
      "        with mean `0` and variance `1` (also called the standard normal\n",
      "        distribution).\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} \\sim \\mathcal{N}(0, 1)\n",
      "        \n",
      "        The shape of the tensor is defined by the variable argument :attr:`size`.\n",
      "        \n",
      "        Args:\n",
      "            size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "                Can be a variable number of arguments or a collection like a list or tuple.\n",
      "            out (Tensor, optional): the output tensor.\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.randn(4)\n",
      "            tensor([-2.1436,  0.9966,  2.3426, -0.6366])\n",
      "            >>> torch.randn(2, 3)\n",
      "            tensor([[ 1.5954,  2.8929, -1.0923],\n",
      "                    [ 1.1719, -0.4709, -0.1996]])\n",
      "    \n",
      "    save(obj, f, pickle_module=<module 'pickle' from 'C:\\\\Users\\\\Salar\\\\Anaconda3\\\\lib\\\\pickle.py'>, pickle_protocol=2, _use_new_zipfile_serialization=False)\n",
      "        Saves an object to a disk file.\n",
      "        \n",
      "        See also: :ref:`recommend-saving-models`\n",
      "        \n",
      "        Args:\n",
      "            obj: saved object\n",
      "            f: a file-like object (has to implement write and flush) or a string\n",
      "               containing a file name\n",
      "            pickle_module: module used for pickling metadata and objects\n",
      "            pickle_protocol: can be specified to override the default protocol\n",
      "        \n",
      "        .. warning::\n",
      "            If you are using Python 2, :func:`torch.save` does NOT support :class:`StringIO.StringIO`\n",
      "            as a valid file-like object. This is because the write method should return\n",
      "            the number of bytes written; :meth:`StringIO.write()` does not do this.\n",
      "        \n",
      "            Please use something like :class:`io.BytesIO` instead.\n",
      "        \n",
      "        Example:\n",
      "            >>> # Save to file\n",
      "            >>> x = torch.tensor([0, 1, 2, 3, 4])\n",
      "            >>> torch.save(x, 'tensor.pt')\n",
      "            >>> # Save to io.BytesIO buffer\n",
      "            >>> buffer = io.BytesIO()\n",
      "            >>> torch.save(x, buffer)\n",
      "    \n",
      "    seed()\n",
      "        Sets the seed for generating random numbers to a non-deterministic\n",
      "        random number. Returns a 64 bit number used to seed the RNG.\n",
      "    \n",
      "    set_anomaly_enabled(...)\n",
      "    \n",
      "    set_default_tensor_type(t)\n",
      "        Sets the default ``torch.Tensor`` type to floating point tensor type\n",
      "        ``t``. This type will also be used as default floating point type for\n",
      "        type inference in :func:`torch.tensor`.\n",
      "        \n",
      "        The default floating point tensor type is initially ``torch.FloatTensor``.\n",
      "        \n",
      "        Args:\n",
      "            t (type or string): the floating point tensor type or its name\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.tensor([1.2, 3]).dtype    # initial default for floating point is torch.float32\n",
      "            torch.float32\n",
      "            >>> torch.set_default_tensor_type(torch.DoubleTensor)\n",
      "            >>> torch.tensor([1.2, 3]).dtype    # a new floating point tensor\n",
      "            torch.float64\n",
      "    \n",
      "    set_flush_denormal(...)\n",
      "        set_flush_denormal(mode) -> bool\n",
      "        \n",
      "        Disables denormal floating numbers on CPU.\n",
      "        \n",
      "        Returns ``True`` if your system supports flushing denormal numbers and it\n",
      "        successfully configures flush denormal mode.  :meth:`~torch.set_flush_denormal`\n",
      "        is only supported on x86 architectures supporting SSE3.\n",
      "        \n",
      "        Args:\n",
      "            mode (bool): Controls whether to enable flush denormal mode or not\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.set_flush_denormal(True)\n",
      "            True\n",
      "            >>> torch.tensor([1e-323], dtype=torch.float64)\n",
      "            tensor([ 0.], dtype=torch.float64)\n",
      "            >>> torch.set_flush_denormal(False)\n",
      "            True\n",
      "            >>> torch.tensor([1e-323], dtype=torch.float64)\n",
      "            tensor(9.88131e-324 *\n",
      "                   [ 1.0000], dtype=torch.float64)\n",
      "    \n",
      "    set_num_interop_threads(...)\n",
      "        set_num_interop_threads(int)\n",
      "        \n",
      "        Sets the number of threads used for interop parallelism\n",
      "        (e.g. in JIT interpreter) on CPU.\n",
      "        WARNING: Can only be called once and before any inter-op parallel work\n",
      "        is started (e.g. JIT execution).\n",
      "    \n",
      "    set_num_threads(...)\n",
      "        set_num_threads(int)\n",
      "        \n",
      "        Sets the number of threads used for intraop parallelism on CPU.\n",
      "        WARNING:\n",
      "        To ensure that the correct number of threads is used, set_num_threads\n",
      "        must be called before running eager, JIT or autograd code.\n",
      "    \n",
      "    set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
      "        Set options for printing. Items shamelessly taken from NumPy\n",
      "        \n",
      "        Args:\n",
      "            precision: Number of digits of precision for floating point output\n",
      "                (default = 4).\n",
      "            threshold: Total number of array elements which trigger summarization\n",
      "                rather than full `repr` (default = 1000).\n",
      "            edgeitems: Number of array items in summary at beginning and end of\n",
      "                each dimension (default = 3).\n",
      "            linewidth: The number of characters per line for the purpose of\n",
      "                inserting line breaks (default = 80). Thresholded matrices will\n",
      "                ignore this parameter.\n",
      "            profile: Sane defaults for pretty printing. Can override with any of\n",
      "                the above options. (any one of `default`, `short`, `full`)\n",
      "            sci_mode: Enable (True) or disable (False) scientific notation. If\n",
      "                None (default) is specified, the value is defined by `_Formatter`\n",
      "    \n",
      "    set_rng_state(new_state)\n",
      "        Sets the random number generator state.\n",
      "        \n",
      "        Args:\n",
      "            new_state (torch.ByteTensor): The desired state\n",
      "    \n",
      "    split(tensor, split_size_or_sections, dim=0)\n",
      "        Splits the tensor into chunks.\n",
      "        \n",
      "        If :attr:`split_size_or_sections` is an integer type, then :attr:`tensor` will\n",
      "        be split into equally sized chunks (if possible). Last chunk will be smaller if\n",
      "        the tensor size along the given dimension :attr:`dim` is not divisible by\n",
      "        :attr:`split_size`.\n",
      "        \n",
      "        If :attr:`split_size_or_sections` is a list, then :attr:`tensor` will be split\n",
      "        into ``len(split_size_or_sections)`` chunks with sizes in :attr:`dim` according\n",
      "        to :attr:`split_size_or_sections`.\n",
      "        \n",
      "        Arguments:\n",
      "            tensor (Tensor): tensor to split.\n",
      "            split_size_or_sections (int) or (list(int)): size of a single chunk or\n",
      "                list of sizes for each chunk\n",
      "            dim (int): dimension along which to split the tensor.\n",
      "    \n",
      "    stack(...)\n",
      "        stack(tensors, dim=0, out=None) -> Tensor\n",
      "        \n",
      "        Concatenates sequence of tensors along a new dimension.\n",
      "        \n",
      "        All tensors need to be of the same size.\n",
      "        \n",
      "        Arguments:\n",
      "            tensors (sequence of Tensors): sequence of tensors to concatenate\n",
      "            dim (int): dimension to insert. Has to be between 0 and the number\n",
      "                of dimensions of concatenated tensors (inclusive)\n",
      "            out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    typename(o)\n",
      "    \n",
      "    wait(...) method of builtins.PyCapsule instance\n",
      "        wait(arg0: torch._C.Future) -> IValue\n",
      "\n",
      "DATA\n",
      "    AVG = AggregationType.AVG\n",
      "    SUM = AggregationType.SUM\n",
      "    __all__ = ['typename', 'is_tensor', 'is_storage', 'set_default_tensor_...\n",
      "    default_generator = <torch._C.Generator object>\n",
      "    has_cuda = True\n",
      "    has_cudnn = True\n",
      "    has_lapack = True\n",
      "    has_mkl = True\n",
      "    has_mkldnn = False\n",
      "    has_openmp = True\n",
      "\n",
      "VERSION\n",
      "    1.4.0\n",
      "\n",
      "FILE\n",
      "    c:\\users\\salar\\anaconda3\\lib\\site-packages\\torch\\__init__.py\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4.5, 5]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'transforms'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-22c315eb2844>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m4.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'transforms'"
     ]
    }
   ],
   "source": [
    "a=[2,3 ,4.5,5]\n",
    "print(a)\n",
    "b=a.transforms.ToTensor()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2384662f651491791f8be0f60060a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac581503152d4023b836611738fc4349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1270eefb6dbe4c688437ce69041d6e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02e17731f1847b083401d6d5c9e7c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\"\",train=True, download=True, transform=transforms.Compose([transforms.ToTensor(),]))\n",
    "test = datasets.MNIST(\"\",train=False, download=True, transform=transforms.Compose([transforms.ToTensor(),]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset=torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000000002FA836D8>\n"
     ]
    }
   ],
   "source": [
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000000002FA56DA0>\n"
     ]
    }
   ],
   "source": [
    "print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000000002FA836D8> <torch.utils.data.dataloader.DataLoader object at 0x000000002FA56DA0>\n"
     ]
    }
   ],
   "source": [
    "print(trainset,testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 7, 2, 2, 8, 7, 0, 5, 7, 7])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    a=data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 7, 2, 2, 8, 7, 0, 5, 7, 7])]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3608, 0.3569, 0.3569,\n",
      "          0.8549, 0.9961, 0.9961, 0.9961, 0.5804, 0.9961, 0.3725, 0.3569,\n",
      "          0.3569, 0.3216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9961, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9647, 0.7059, 0.7059, 0.7059, 0.1333, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9961, 0.9922, 0.9922,\n",
      "          0.6667, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.5725, 0.8588,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8627, 0.4196, 0.0275,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.2196, 0.2196,\n",
      "          0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529,\n",
      "          0.2196, 0.2196, 0.2196, 0.7412, 0.9294, 0.9922, 0.9922, 0.0588,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.5137, 0.9922, 0.9922, 0.0588,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0353, 0.6078, 0.9922, 0.9922, 0.0588,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5137, 0.9922, 0.9922, 0.9922, 0.0588,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1176, 0.8549, 0.9922, 0.7647, 0.3608, 0.0078,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.4588, 0.7843, 0.9922, 0.9922, 0.1255, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118,\n",
      "          0.5725, 0.9843, 0.9922, 0.7294, 0.3373, 0.0039, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353, 0.4863,\n",
      "          0.9922, 0.9922, 0.9765, 0.1843, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1020, 0.3882, 0.9765, 0.9922,\n",
      "          0.9922, 0.7020, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0196, 0.4549, 0.8039, 0.9922, 0.9922, 0.9255,\n",
      "          0.6431, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0588, 0.4549, 0.5569, 0.9922, 0.9922, 0.9922, 0.8431, 0.1725,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.4353,\n",
      "          0.8275, 0.9922, 0.9922, 0.9922, 0.8431, 0.4353, 0.1294, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1882, 0.5451, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.7059, 0.0471, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9255, 0.2863, 0.2275, 0.2275, 0.2275,\n",
      "          0.2275, 0.2275, 0.2275, 0.2275, 0.2275, 0.0314, 0.1333, 0.2275,\n",
      "          0.2275, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.6314, 0.8196, 0.9922,\n",
      "          0.9922, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2902, 0.7020, 0.7020,\n",
      "          0.7020, 0.7020, 0.7020, 0.7020, 0.9647, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.8039, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.3490, 0.3490, 0.7882,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.4314, 0.3490, 0.3490,\n",
      "          0.1255, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "x,y =data[0][0],data[1][0]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3792d518>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=0\n",
    "count_dict={0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "for data in trainset:\n",
    "    xs,ys=data\n",
    "    for y in ys:\n",
    "        count_dict[int(y)]+=1\n",
    "        total+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(count_dict)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-508713d18093>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "kk=float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(28*28, 64)\n",
    "        self.fc2=nn.Linear(64, 64)\n",
    "        self.fc3=nn.Linear(64, 64)\n",
    "        self.fc4=nn.Linear(64, 10)\n",
    "       \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        x=self.fc4(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "net=Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.rand((28,28))\n",
    "X=X.view(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2037, -2.3326, -2.1997, -2.3772, -2.3583, -2.2936, -2.2976, -2.2334,\n",
       "         -2.3990, -2.3544]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0282, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer= optim.Adam(net.parameters(),lr=0.001)\n",
    "EPOCHS=3\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:    #data is a batch of featuresets and lables\n",
    "        X,y =data\n",
    "        net.zero_grad()\n",
    "        output=net(X.view(-1,28*28))\n",
    "        loss=F.nll_loss(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X,y =data\n",
    "        output=net(X.view(-1,28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i)==y[idx]:\n",
    "                correct+=1\n",
    "            total+=1\n",
    "            \n",
    "print(\"Accuracy:\", round(correct/total,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[1].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[1].view(-1,28*28))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
